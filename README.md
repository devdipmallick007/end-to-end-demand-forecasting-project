# end-to-end-demand-forecasting-project
ğŸ“¦ Demand Forecasting System (End-to-End ML Pipeline)

An end-to-end production-ready Demand Forecasting System built with Python, XGBoost, MLflow, Redis caching, multithreading, SQL database integration, external API enrichment, and a modular data pipeline.
The system predicts daily sales quantity for Blinkit-style retail data using advanced feature engineering and time-series modeling.


ğŸš€ Overview

This project implements a complete machine learning workflow:

âœ” Multi-table SQL data ingestion
âœ” Geocoding & weather API enrichment
âœ” Redis caching for API optimization
âœ” Multithreading for fast external API calls
âœ” Table-wise cleaning and feature engineering
âœ” Time-series feature engineering
âœ” Full EDA dashboard support
âœ” XGBoost time-series forecasting
âœ” RMSE & MAE evaluation
âœ” MLflow experiment tracking
âœ” Centralized logging
âœ” End-to-end pipeline execution using run_pipeline.py

ğŸ—‚ Project Structure

demand_forecasting_system/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ cleaned/
â”‚   â”œâ”€â”€ feature/
â”‚   â”œâ”€â”€ final_data/
â”‚   |â”€â”€ merge/
|   â””â”€â”€ forecast/
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ pipeline.log
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_extraction/
â”‚   â”œâ”€â”€ data_pipeline/
|   |   â”œâ”€â”€ data_clean/
â”‚   |   â”œâ”€â”€ feature_engineering/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ utils/
|   â”œâ”€â”€ task/
|   â”œâ”€â”€ mlruns/
|   â”œâ”€â”€ config/
|   â”‚ 
â”‚   â”‚â”€â”€clean_data.py   
|   â”‚â”€â”€main_feature.py   
|   â”‚â”€â”€featch_data.py   
|   â”‚â”€â”€model.py   
|  
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ forecast.py
â”‚
|â”€â”€ README.md
â””â”€â”€ run_pipeline.py

ğŸ—„ 1. Data Sources

The following SQL tables are used:

blinkit_customers

blinkit_delivery_performance

blinkit_marketing_performance

blinkit_order_items

blinkit_orders

blinkit_products

Plus one CSV file:

blinkit_inventory.csv

These collectively build the full operational dataset for forecasting.


ğŸŒ 2. Data Extraction + External API Enrichment
Geocoding API

Uses customer/store area information

Fetches latitude and longitude

Weather API

Fetches historical weather for each date

Temperature, humidity, rainfall, etc.

Redis Caching

Avoids repeated requests for same location+date

Boosts pipeline performance

Multithreading

Parallel API calls for large datasets

Improves speed during data enrichment


ğŸ§¹ 3. Table-wise Data Cleaning

Each table is cleaned using clean_data.py:

Handle missing values

Remove duplicates

Fix datatypes

Correct inconsistent values

Standardize date formats

Apply table-specific business rules

Cleaned outputs are stored in:

data/cleaned/

ğŸ— 4. Feature Engineering
A. Table-wise Feature Engineering

Each cleaned table undergoes feature engineering:

Delivery performance metrics

Customer behavior features

Product-level attributes

Marketing indicators

Inventory transformations

Stored in:

data/feature/

B. Time-Series Feature Engineering (Global Merge)

Executed using main_feature.py after merging all tables:

Lag features: 1, 2, 3, 7, 14, 21, 28 days

Rolling means: 3, 7, 14, 28 days

Trend & seasonal signatures

Calendar features (month, day, week, holiday flags)

Product/store/category-level aggregations

Final dataset stored in:

data/final_data/



ğŸ“Š 5. Exploratory Data Analysis (EDA)

Performed after merging all features:

Time-series trend

Seasonal patterns

Product/category insights

Revenue & quantity distributions

Correlations

An optional Flask dashboard can be used for interactive EDA.



ğŸ¤– 6. Modeling (XGBoost)

The forecasting model uses XGBoost Regressor:

Train/test split

Fit on engineered time-series features

Daily sales prediction

Future forecasting (7â€“30 days configurable)

The trained model is saved automatically.



ğŸ“ˆ 7. Model Evaluation

Two key evaluation metrics:

RMSE (Root Mean Squared Error)

MAE (Mean Absolute Error)

Both metrics are:

âœ” Printed
âœ” Logged locally
âœ” Logged to MLflow



ğŸ“¦ 8. MLflow Integration

MLflow is used for:

Parameters

Model type

Horizon days

Training configuration

Metrics

RMSE

MAE

Artifacts

Model pickle file

Forecast files

Optional charts

MLflow experiment:

store_brand_product_forecast


Helps compare models and maintain traceability.



ğŸ“œ 9. Logging System

Every stage logs:

Start/end timestamps

Info messages

Warning & error logs

MLflow sync status

Logs stored in:

logs/pipeline.log



â–¶ï¸ 10. End-to-End Pipeline Execution

Run the full system with:

python run_pipeline.py


This triggers:

Data extraction

Geocoding + weather enrichment

Caching

Cleaning

Feature engineering

Merge

Time-series engineering

Modeling

Evaluation

Forecast generation

Logging

MLflow tracking


ğŸ§ª 11. Requirements
pandas
numpy
sqlalchemy
requests
redis
xgboost
mlflow
scikit-learn
statsmodels
plotly
flask
pyyaml


Install:

pip install -r requirements.txt


ğŸ“¸ 12. Future Enhancements

CI/CD with GitHub Actions

Automated retraining pipeline

Model registry + deployment pipeline

Real-time inference API

Feature store integration

ğŸ™Œ 
Devdip Mallick
